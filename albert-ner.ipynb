{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用`AlBert`进行命名实体识别\n",
    "***\n",
    "***\n",
    "Time: 2020-09-21\n",
    "Author: dsy\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模块库导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tud # 自定义数据集 \n",
    "import math\n",
    "import pandas as pd\n",
    "from model.torchcrf import CRF\n",
    "import os\n",
    "from model.albert_pytorch.modeling_albert import AlbertConfig, AlbertForPreTraining,AlbertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常量定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model/albert_pytorch/prev_trained_model/albert_base_v2/config.json'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = 202\n",
    "BATCH_SIZE = 8\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "config_file = \"model/albert_pytorch/prev_trained_model/albert_base_v2/config.json\"\n",
    "config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# config = AlbertConfig.from_pretrained(config_file)\n",
    "# # print(\"Building PyTorch model from configuration: {}\".format(str(config)))\n",
    "# model = AlbertForPreTraining(config)\n",
    "# Load weights from tf checkpoint\n",
    "\n",
    "# Save pytorch-model\n",
    "# print(\"Save PyTorch model to {}\".format(pytorch_dump_path))\n",
    "# torch.save(model.state_dict(), pytorch_dump_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建vocab\n",
    "def readVocab(filepath:str=\"data/vocab.txt\"):\n",
    "    vocab = []\n",
    "    with open(filepath,\"r\",encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            vocab.append(line.strip())\n",
    "            \n",
    "    with open(\"data/train.txt\",\"r\",encoding=\"utf-8\") as fp:\n",
    "        for line in fp:\n",
    "            if '' != line.strip():\n",
    "                vocab.append(line.strip().split(\" \")[0])\n",
    "            \n",
    "    vocab = set(vocab)        \n",
    "    vocab2id = { data:1+i for i,data in enumerate(vocab)}\n",
    "    id2vocab = {1+i:data for i,data in enumerate(vocab)}\n",
    "    return (vocab,vocab2id,id2vocab,len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle(filepath:str=\"data/train.txt\"):\n",
    "    words = []\n",
    "    labels = []\n",
    "    vocab = []\n",
    "    label_list = set()\n",
    "    label_list.add(\"[CLS]\")\n",
    "    label_list.add(\"[SEP]\")\n",
    "    with open(filepath,\"r\",encoding=\"utf-8\") as fp:\n",
    "        word = []\n",
    "        label = []\n",
    "        for index,line in enumerate( fp):\n",
    "            \n",
    "            if '' == line.strip():\n",
    "                words.append(word)\n",
    "                labels.append(label)\n",
    "#                 print(\"words:\\n\",pd.DataFrame(words))\n",
    "#                 print(\"labels:\\n\",pd.DataFrame(labels))\n",
    "                word = []\n",
    "                label = []\n",
    "            else:\n",
    "                linesplit = line.strip().split(\" \")\n",
    "                word.append(linesplit[0])\n",
    "                label.append(linesplit[1])\n",
    "                label_list.add(linesplit[1])\n",
    "                \n",
    "    label2id = {data:i+1 for i,data in enumerate(label_list)}\n",
    "    id2label = {1+i:data for i,data in enumerate(label_list)}\n",
    "    \n",
    "    input_ids = []\n",
    "    for i in words:\n",
    "        input_id = []\n",
    "    #     break\n",
    "        for j in i:\n",
    "            input_id.append(vocab2id[j])\n",
    "    #         break\n",
    "\n",
    "        if len(input_id) > ( max_seq_length - 2):\n",
    "            input_id = input_id[:max_seq_length - 2]\n",
    "        input_id.insert(0,vocab2id[\"[CLS]\"])   \n",
    "        while len(input_id) < (max_seq_length - 1):\n",
    "            input_id.append(0)\n",
    "        input_id.append(vocab2id[\"[SEP]\"])\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        \n",
    "    label_ids = []\n",
    "    for i in labels:\n",
    "        label_id = []\n",
    "    #     break\n",
    "        for j in i:\n",
    "            label_id.append(label2id[j])\n",
    "    #         break\n",
    "\n",
    "        if len(label_id) > ( max_seq_length - 2):\n",
    "            label_id = label_id[:max_seq_length - 2]\n",
    "        label_id.insert(0,label2id[\"[CLS]\"])   \n",
    "        while len(label_id) < (max_seq_length - 1):\n",
    "            label_id.append(0)\n",
    "        label_id.append(label2id[\"[SEP]\"])\n",
    "\n",
    "        label_ids.append(label_id)\n",
    "\n",
    "    return (words,labels,label_list,label2id,id2label,len(label_list),input_ids,label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(vocab,vocab2id,id2vocab,vocab_size)= readVocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words,labels,label_list,label2id,id2label,label_size,input_ids,label_ids = handle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.Tensor(input_ids).long()\n",
    "label_ids = torch.Tensor(label_ids).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertNerDataset(tud.Dataset): \n",
    "    def __init__(self,input_ids,label_ids): \n",
    "        super(BertNerDataset,self).__init__() \n",
    "        self.label_ids = label_ids\n",
    "        self.input_ids = input_ids\n",
    "       \n",
    "    def __len__(self): \n",
    "        return len(self.input_ids) \n",
    "    def __getitem__(self, index): \n",
    "        return (self.input_ids[index,:],self.label_ids[index,:])\n",
    "\n",
    "dataset = BertNerDataset(input_ids[:8000],label_ids[:8000]) \n",
    "dataloader = tud.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlBertCRFNer(nn.Module):\n",
    "    '''\n",
    "    AlBert + CRF\n",
    "    '''\n",
    "    def __init__(self,vocab_size,config_file,num_tags=768):\n",
    "        \n",
    "        super(AlBertCRFNer,self).__init__()\n",
    "        config = AlbertConfig.from_pretrained(config_file)\n",
    "        self.albert = AlbertModel(config)\n",
    "        self.crf = CRF(num_tags)\n",
    "\n",
    "    def forward(self,x,tags=None):\n",
    "        y,_= self.albert(x) # 8,202,768\n",
    "        if tags is None:\n",
    "            output = y.permute(1,0,2)\n",
    "            return self.crf.decode(output) # 8 202\n",
    "        else:\n",
    "            return -self.crf(y,tags,reduction='mean') # (seq_length, batch_size, num_tags)   (seq_length, batch_size)--> (batch_size,).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlBertBiLSTMCRFNer(nn.Module):\n",
    "    '''\n",
    "    AlBert + BiLSTM + CRF\n",
    "    '''\n",
    "    def __init__(self,vocab_size,config_file,num_tags=768):\n",
    "        super(AlBertBiLSTMCRFNer,self).__init__()\n",
    "        config = AlbertConfig.from_pretrained(config_file)\n",
    "        self.albert = AlbertModel(config)\n",
    "        self.bilstm = nn.LSTM(input_size = 768,hidden_size =768 //2, bidirectional =True)\n",
    "        self.crf = CRF(num_tags)\n",
    "        \n",
    "    def forward(self,x,tags=None):\n",
    "        y,_=  self.albert(x)\n",
    "        output,_ = self.bilstm(y) # 8 202 768\n",
    "        \n",
    "        if tags is None:\n",
    "            output = output.permute(1,0,2)\n",
    "            return self.crf.decode(output) # 8 202\n",
    "        else:\n",
    "            return -self.crf(output,tags,reduction='mean') # (seq_length, batch_size, num_tags)   (seq_length, batch_size)--> (batch_size,).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlBertBiGRUCRFNer(nn.Module):\n",
    "    '''\n",
    "    AlBert + BiGRU + CRF\n",
    "    '''\n",
    "    def __init__(self,vocab_size,config_file,num_tags=768):\n",
    "        super(AlBertBiGRUCRFNer,self).__init__()\n",
    "        config = AlbertConfig.from_pretrained(config_file)\n",
    "        self.albert = AlbertModel(config)\n",
    "        self.bigru = nn.GRU(input_size=768,hidden_size=768//2,bidirectional=True)\n",
    "        self.crf = CRF(num_tags)\n",
    "\n",
    "    def forward(self,x,tags=None):\n",
    "            \n",
    "        y,_ = self.albert(x)\n",
    "        output,_ = self.bigru(y)  \n",
    "        \n",
    "        if tags is None:\n",
    "            output = output.permute(1,0,2) \n",
    "            return self.crf.decode(output)\n",
    "        else:\n",
    "            return -self.crf(output,tags,reduction='mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自注意模型\n",
    "from  torch.nn.parameter import Parameter\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self,embed_dim):\n",
    "        super(SelfAttention,self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.selfattention = nn.MultiheadAttention(embed_dim, num_heads=1, dropout=0.0, bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        L,N,E = x.shape\n",
    "        W1 = Parameter(torch.empty((L,N,N)))\n",
    "        W2 = Parameter(torch.empty((L,N,N)))\n",
    "        W3 = Parameter(torch.empty((L,N,N)))\n",
    "        \n",
    "        std = 1./ math.sqrt(self.embed_dim)\n",
    "        \n",
    "        nn.init.uniform_(W1,-std,std)\n",
    "        nn.init.uniform_(W2,-std,std)\n",
    "        nn.init.uniform_(W3,-std,std)\n",
    "        \n",
    "        query = W1.matmul(x) # (L, N, E)\n",
    "        key = W2.matmul(x) # (S,N,E)\n",
    "        value = W3.matmul(x) # (S,N,E)\n",
    "        attn_output,_ = self.selfattention(query, key, value) # (L,N,E)\n",
    "        return attn_output\n",
    "    \n",
    "class AlBertBiGRUSelfAttentionCRFNer(nn.Module):\n",
    "    '''\n",
    "    AlBert + BiGRU + self-attention + CRF\n",
    "    '''\n",
    "    def __init__(self,vocab_size,config_file,embed_dim=768,num_tags=768):\n",
    "        super(AlBertBiGRUSelfAttentionCRFNer,self).__init__()\n",
    "        config = AlbertConfig.from_pretrained(config_file)\n",
    "        self.albert = AlbertModel(config)\n",
    "        self.bigru = nn.GRU(input_size=768,hidden_size=768//2,bidirectional=True)\n",
    "        self.selfattention = SelfAttention(embed_dim)\n",
    "        self.crf = CRF(num_tags)\n",
    "\n",
    "    def forward(self,x,tags=None):\n",
    "        y = self.albert(x)\n",
    "        output,_ = self.bigru(y)\n",
    "        output = self.selfattention(output) # 8 202 768\n",
    "        if tags is None:\n",
    "            output = output.permute(1,0,2) \n",
    "            return self.crf.decode(output)\n",
    "        else:\n",
    "            return -self.crf(output,tags,reduction='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameList = [\n",
    "    'AlBert-CRF',\n",
    "    'AlBert-BiLSTM-CRF',\n",
    "    'AlBert-BiGRU-CRF', \n",
    "    'AlBert-BiGRU-selfattentin-CRF'\n",
    "]\n",
    "modelList = [\n",
    "    AlBertCRFNer(vocab_size,config_file) ,\n",
    "    AlBertBiLSTMCRFNer(vocab_size,config_file),\n",
    "    AlBertBiGRUCRFNer(vocab_size,config_file),\n",
    "    AlBertBiGRUSelfAttentionCRFNer(vocab_size,config_file)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: AlBert-CRF epoch: 0 step: 10 ,loss: 29.66684913635254\n",
      "model name: AlBert-CRF epoch: 0 step: 20 ,loss: 4.569178581237793\n",
      "model name: AlBert-CRF epoch: 0 step: 30 ,loss: 5.719108581542969\n",
      "model name: AlBert-CRF epoch: 0 step: 40 ,loss: 4.686387062072754\n",
      "model name: AlBert-CRF epoch: 0 step: 50 ,loss: 3.9020111560821533\n",
      "model name: AlBert-CRF epoch: 0 step: 60 ,loss: 4.2586140632629395\n",
      "model name: AlBert-CRF epoch: 0 step: 70 ,loss: 4.523194313049316\n",
      "model name: AlBert-CRF epoch: 0 step: 80 ,loss: 2.929595947265625\n",
      "model name: AlBert-CRF epoch: 0 step: 90 ,loss: 3.9714808464050293\n",
      "model name: AlBert-CRF epoch: 0 step: 100 ,loss: 6.160427570343018\n",
      "model name: AlBert-CRF epoch: 0 step: 110 ,loss: 5.508391857147217\n",
      "model name: AlBert-CRF epoch: 0 step: 120 ,loss: 4.375628471374512\n",
      "model name: AlBert-CRF epoch: 0 step: 130 ,loss: 3.947162389755249\n",
      "model name: AlBert-CRF epoch: 0 step: 140 ,loss: 3.766493320465088\n",
      "model name: AlBert-CRF epoch: 0 step: 150 ,loss: 3.021801233291626\n",
      "model name: AlBert-CRF epoch: 0 step: 160 ,loss: 3.3547914028167725\n",
      "model name: AlBert-CRF epoch: 0 step: 170 ,loss: 4.39995002746582\n",
      "model name: AlBert-CRF epoch: 0 step: 180 ,loss: 4.027573585510254\n",
      "model name: AlBert-CRF epoch: 0 step: 190 ,loss: 4.800992965698242\n",
      "model name: AlBert-CRF epoch: 0 step: 200 ,loss: 5.018339157104492\n",
      "model name: AlBert-CRF epoch: 0 step: 210 ,loss: 4.4620680809021\n",
      "model name: AlBert-CRF epoch: 0 step: 220 ,loss: 7.090382099151611\n",
      "model name: AlBert-CRF epoch: 0 step: 230 ,loss: 3.7484853267669678\n",
      "model name: AlBert-CRF epoch: 0 step: 240 ,loss: 5.396233558654785\n",
      "model name: AlBert-CRF epoch: 0 step: 250 ,loss: 4.566507339477539\n",
      "model name: AlBert-CRF epoch: 0 step: 260 ,loss: 3.4259228706359863\n",
      "model name: AlBert-CRF epoch: 0 step: 270 ,loss: 3.6510276794433594\n",
      "model name: AlBert-CRF epoch: 0 step: 280 ,loss: 3.0317206382751465\n",
      "model name: AlBert-CRF epoch: 0 step: 290 ,loss: 3.1695938110351562\n",
      "model name: AlBert-CRF epoch: 0 step: 300 ,loss: 3.4292666912078857\n",
      "model name: AlBert-CRF epoch: 0 step: 310 ,loss: 4.926335334777832\n",
      "model name: AlBert-CRF epoch: 0 step: 320 ,loss: 4.078118801116943\n",
      "model name: AlBert-CRF epoch: 0 step: 330 ,loss: 5.445553779602051\n",
      "model name: AlBert-CRF epoch: 0 step: 340 ,loss: 5.506412506103516\n",
      "model name: AlBert-CRF epoch: 0 step: 350 ,loss: 3.817509651184082\n",
      "model name: AlBert-CRF epoch: 0 step: 360 ,loss: 6.491064548492432\n",
      "model name: AlBert-CRF epoch: 0 step: 370 ,loss: 4.308493614196777\n",
      "model name: AlBert-CRF epoch: 0 step: 380 ,loss: 3.3500194549560547\n",
      "model name: AlBert-CRF epoch: 0 step: 390 ,loss: 4.914005279541016\n",
      "model name: AlBert-CRF epoch: 0 step: 400 ,loss: 3.366550922393799\n",
      "model name: AlBert-CRF epoch: 0 step: 410 ,loss: 2.922825336456299\n",
      "model name: AlBert-CRF epoch: 0 step: 420 ,loss: 2.8615870475769043\n",
      "model name: AlBert-CRF epoch: 0 step: 430 ,loss: 3.098443031311035\n",
      "model name: AlBert-CRF epoch: 0 step: 440 ,loss: 4.35982608795166\n",
      "model name: AlBert-CRF epoch: 0 step: 450 ,loss: 4.808663368225098\n",
      "model name: AlBert-CRF epoch: 0 step: 460 ,loss: 3.1608822345733643\n",
      "model name: AlBert-CRF epoch: 0 step: 470 ,loss: 3.4830634593963623\n",
      "model name: AlBert-CRF epoch: 0 step: 480 ,loss: 6.742470741271973\n",
      "model name: AlBert-CRF epoch: 0 step: 490 ,loss: 3.3611531257629395\n",
      "model name: AlBert-CRF epoch: 0 step: 500 ,loss: 3.550671339035034\n",
      "model name: AlBert-CRF epoch: 0 step: 510 ,loss: 3.310943603515625\n",
      "model name: AlBert-CRF epoch: 0 step: 520 ,loss: 3.736987352371216\n",
      "model name: AlBert-CRF epoch: 0 step: 530 ,loss: 4.390737533569336\n",
      "model name: AlBert-CRF epoch: 0 step: 540 ,loss: 3.7382686138153076\n",
      "model name: AlBert-CRF epoch: 0 step: 550 ,loss: 4.441886901855469\n",
      "model name: AlBert-CRF epoch: 0 step: 560 ,loss: 4.8065505027771\n",
      "model name: AlBert-CRF epoch: 0 step: 570 ,loss: 4.5396575927734375\n",
      "model name: AlBert-CRF epoch: 0 step: 580 ,loss: 2.905611753463745\n",
      "model name: AlBert-CRF epoch: 0 step: 590 ,loss: 4.674705505371094\n",
      "model name: AlBert-CRF epoch: 0 step: 600 ,loss: 4.807281017303467\n",
      "model name: AlBert-CRF epoch: 0 step: 610 ,loss: 5.514001369476318\n",
      "model name: AlBert-CRF epoch: 0 step: 620 ,loss: 4.495265960693359\n",
      "model name: AlBert-CRF epoch: 0 step: 630 ,loss: 3.7755088806152344\n",
      "model name: AlBert-CRF epoch: 0 step: 640 ,loss: 3.2675976753234863\n",
      "model name: AlBert-CRF epoch: 0 step: 650 ,loss: 3.1765239238739014\n",
      "model name: AlBert-CRF epoch: 0 step: 660 ,loss: 4.432689189910889\n",
      "model name: AlBert-CRF epoch: 0 step: 670 ,loss: 4.25200891494751\n",
      "model name: AlBert-CRF epoch: 0 step: 680 ,loss: 3.6618189811706543\n",
      "model name: AlBert-CRF epoch: 0 step: 690 ,loss: 3.7982370853424072\n",
      "model name: AlBert-CRF epoch: 0 step: 700 ,loss: 4.042409420013428\n",
      "model name: AlBert-CRF epoch: 0 step: 710 ,loss: 4.367835521697998\n",
      "model name: AlBert-CRF epoch: 0 step: 720 ,loss: 3.795457363128662\n",
      "model name: AlBert-CRF epoch: 0 step: 730 ,loss: 3.8813328742980957\n",
      "model name: AlBert-CRF epoch: 0 step: 740 ,loss: 3.2706356048583984\n",
      "model name: AlBert-CRF epoch: 0 step: 750 ,loss: 4.068025588989258\n",
      "model name: AlBert-CRF epoch: 0 step: 760 ,loss: 4.213980197906494\n",
      "model name: AlBert-CRF epoch: 0 step: 770 ,loss: 4.945570468902588\n",
      "model name: AlBert-CRF epoch: 0 step: 780 ,loss: 2.999298334121704\n",
      "model name: AlBert-CRF epoch: 0 step: 790 ,loss: 3.389178514480591\n",
      "model name: AlBert-CRF epoch: 0 step: 800 ,loss: 3.9740521907806396\n",
      "model name: AlBert-CRF epoch: 0 step: 810 ,loss: 5.014010429382324\n",
      "model name: AlBert-CRF epoch: 0 step: 820 ,loss: 3.739650011062622\n",
      "model name: AlBert-CRF epoch: 0 step: 830 ,loss: 3.0354225635528564\n",
      "model name: AlBert-CRF epoch: 0 step: 840 ,loss: 2.9457573890686035\n",
      "model name: AlBert-CRF epoch: 0 step: 850 ,loss: 3.4365487098693848\n",
      "model name: AlBert-CRF epoch: 0 step: 860 ,loss: 5.147552013397217\n",
      "model name: AlBert-CRF epoch: 0 step: 870 ,loss: 4.409362316131592\n",
      "model name: AlBert-CRF epoch: 0 step: 880 ,loss: 2.7392258644104004\n",
      "model name: AlBert-CRF epoch: 0 step: 890 ,loss: 4.107857704162598\n",
      "model name: AlBert-CRF epoch: 0 step: 900 ,loss: 4.636776924133301\n",
      "model name: AlBert-CRF epoch: 0 step: 910 ,loss: 2.7167413234710693\n",
      "model name: AlBert-CRF epoch: 0 step: 920 ,loss: 4.436450004577637\n",
      "model name: AlBert-CRF epoch: 0 step: 930 ,loss: 4.932549953460693\n",
      "model name: AlBert-CRF epoch: 0 step: 940 ,loss: 3.42893385887146\n",
      "model name: AlBert-CRF epoch: 0 step: 950 ,loss: 3.6412384510040283\n",
      "model name: AlBert-CRF epoch: 0 step: 960 ,loss: 5.4585394859313965\n",
      "model name: AlBert-CRF epoch: 0 step: 970 ,loss: 4.633519649505615\n",
      "model name: AlBert-CRF epoch: 0 step: 980 ,loss: 3.2559053897857666\n",
      "model name: AlBert-CRF epoch: 0 step: 990 ,loss: 5.427216053009033\n",
      "model name: AlBert-CRF epoch: 0 step: 1000 ,loss: 4.259253978729248\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 10 ,loss: 35.7457275390625\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 20 ,loss: 26.952302932739258\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 30 ,loss: 18.691072463989258\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 40 ,loss: 10.75196647644043\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 50 ,loss: 5.784682273864746\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 60 ,loss: 3.6679158210754395\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 70 ,loss: 4.7324724197387695\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 80 ,loss: 5.349799156188965\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 90 ,loss: 2.6895947456359863\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 100 ,loss: 5.145920753479004\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 110 ,loss: 3.1143686771392822\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 120 ,loss: 4.555789947509766\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 130 ,loss: 4.149621963500977\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 140 ,loss: 4.3232598304748535\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 150 ,loss: 3.0513453483581543\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 160 ,loss: 3.9533309936523438\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 170 ,loss: 3.4857354164123535\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 180 ,loss: 3.0966038703918457\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 190 ,loss: 4.213615417480469\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 200 ,loss: 3.809497594833374\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 210 ,loss: 5.067317008972168\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 220 ,loss: 2.8308188915252686\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 230 ,loss: 4.0243706703186035\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 240 ,loss: 3.7117083072662354\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 250 ,loss: 3.198890209197998\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 260 ,loss: 3.2654495239257812\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 270 ,loss: 5.495079040527344\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 280 ,loss: 4.16360330581665\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 290 ,loss: 4.959422588348389\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 300 ,loss: 3.1948392391204834\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 310 ,loss: 5.273039817810059\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 320 ,loss: 4.485421657562256\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 330 ,loss: 3.5894830226898193\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 340 ,loss: 2.854452610015869\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 350 ,loss: 4.332266807556152\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 360 ,loss: 3.4728846549987793\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 370 ,loss: 2.9036805629730225\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 380 ,loss: 3.6532649993896484\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 390 ,loss: 6.087786674499512\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 400 ,loss: 4.6785383224487305\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 410 ,loss: 3.300762891769409\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 420 ,loss: 3.3218395709991455\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 430 ,loss: 4.106171607971191\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 440 ,loss: 5.319361209869385\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 450 ,loss: 3.22135853767395\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 460 ,loss: 5.196117877960205\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 470 ,loss: 3.802427053451538\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 480 ,loss: 3.259770393371582\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 490 ,loss: 4.765261650085449\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 500 ,loss: 7.533969879150391\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 510 ,loss: 2.5082709789276123\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 520 ,loss: 4.029984474182129\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 530 ,loss: 3.983501434326172\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 540 ,loss: 4.273597240447998\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 550 ,loss: 4.16765832901001\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 560 ,loss: 3.808626651763916\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 570 ,loss: 2.7996091842651367\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 580 ,loss: 5.2094831466674805\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 590 ,loss: 4.576986789703369\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 600 ,loss: 3.4181110858917236\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 610 ,loss: 3.640491485595703\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 620 ,loss: 4.4509453773498535\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 630 ,loss: 3.592402696609497\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 640 ,loss: 6.009159564971924\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 650 ,loss: 3.788377285003662\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 660 ,loss: 3.275975227355957\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 670 ,loss: 3.986537218093872\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 680 ,loss: 3.8256711959838867\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 690 ,loss: 6.708785057067871\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 700 ,loss: 5.561286926269531\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 710 ,loss: 3.7624881267547607\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 720 ,loss: 4.130307197570801\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 730 ,loss: 2.250131130218506\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 740 ,loss: 4.1922287940979\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 750 ,loss: 4.608191013336182\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 760 ,loss: 3.9199888706207275\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 770 ,loss: 5.173701286315918\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 780 ,loss: 3.6147654056549072\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 790 ,loss: 6.459507942199707\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 800 ,loss: 4.443574905395508\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 810 ,loss: 3.909923791885376\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 820 ,loss: 2.562229871749878\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 830 ,loss: 3.373537063598633\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 840 ,loss: 2.719655752182007\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 850 ,loss: 3.502840757369995\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 860 ,loss: 5.00573205947876\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 870 ,loss: 4.010712623596191\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 880 ,loss: 3.166400671005249\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 890 ,loss: 3.972771167755127\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 900 ,loss: 7.0355706214904785\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 910 ,loss: 3.9049887657165527\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 920 ,loss: 4.374194622039795\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 930 ,loss: 3.514799118041992\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 940 ,loss: 4.01977014541626\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 950 ,loss: 4.685234546661377\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 960 ,loss: 3.0938751697540283\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 970 ,loss: 3.6607460975646973\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 980 ,loss: 3.9443280696868896\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 990 ,loss: 2.55104923248291\n",
      "model name: AlBert-BiLSTM-CRF epoch: 0 step: 1000 ,loss: 2.7012693881988525\n"
     ]
    }
   ],
   "source": [
    "for index,model in enumerate(modelList):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05)   # optimize all parameters\n",
    "    lossDataFrame = pd.DataFrame()\n",
    "# loss_func = nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
    "    for epoch in range(EPOCH):\n",
    "        for step,(input_ids,label_ids) in enumerate(dataloader):\n",
    "            #x,tags=None,segment_ids=None\n",
    "    #         y_pred = bertcrfner(input_ids,label_ids,torch.zeros(input_ids.size()).long())\n",
    "    #         print(\"y_pred\",y_pred.shape)\n",
    "    #         print(\"label_ids\",label_ids.shape)\n",
    "    #         loss = loss_func(y_pred,label_ids)\n",
    "\n",
    "            loss = model(input_ids,label_ids)\n",
    "            if 0 == (step+1) % 10 :\n",
    "                lossDataFrame.loc[(epoch + 1) * ((step + 1)//10),nameList[index]] = loss.item()\n",
    "                print(\"model name:\",nameList[index],\"epoch:\",epoch,\"step:\",step+1,\",loss:\",loss.item())\n",
    "\n",
    "            optimizer.zero_grad()           # clear gradients for this training step\n",
    "            loss.backward()                 # backpropagation, compute gradients\n",
    "            optimizer.step()                # apply gradient\n",
    "#             break\n",
    "#     break\n",
    "    torch.save(model.state_dict(), nameList[index]+\".pt\")\n",
    "\n",
    "    lossDataFrame.to_csv(nameList[index]+\"_loss_of_ner.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
